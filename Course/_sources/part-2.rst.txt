1.2. What Is an Agent
=====================

The core element in a multiagent system is the agent. An agent is always situated in a *environment*. The environment can be understood as "everything outside the agent", although this definition is largely inaccurate. People say that the agent *interacts* with the environment, which also can have many different meanings. Let us try to clarify all this.

1. Procedural Reasoning System
------------------------------

The basic model of an agent is the `Procedural Reasoning System <https://hal.laas.fr/hal-01980071/document>`_ (PRS) proposed by Georgeff in 1989 and illustrated on the figure below:

.. figure:: img/PRS.png
    :align: center

    The Procedural Reasoning System - *Georgeff, M.P., and Ingrand, F.F. (1989). Decision-making in an embedded reasoning system. Proc. 11th IJCAI, pp. 972-978*

In this model, the first object to consider is the **environment**. The environment is characterised by a (partially) observable state, which means that 1) it can be modified and 2) some of the variable values can be observed by the agents. As a consequence, an environment is always provided with a set of observation functions and a set of modification functions.

In the PRS model, the agent accesses the observation function through its *sensors*, and the modification functions through its *actuators*. One can easily imagine that different agents in the system can have different sensors and actuators and, thus, different capabilities. Concretely, this means that the agent has some code that calls the observation and modification functions. It is not clear now what exactly this code should be but you could say that the following piece of code implements the beginning of an agent-environment pair.

.. code:: python

    environment_variable = 0

    def operation_increase_variable():
        global environment_variable
        environment_variable += 1

    def perception_get_variable():
        global environment_variable
        return environment_variable

    def agent(preferred_value):
        v = perception_get_variable() # this is a sensor
        while (v<preferred_value):
            operation_increase_variable() # this is an actuator
            v = perception_get_variable()

However, the most important aspect of the PRS model is the **procedural loop**. An agent runs continuously in three steps:

1. Perception of the environment
2. Deliberation = selection of the action
3. Action on the environment

This structure is at the core of a multiagent system. It makes it possible to have asynchronous runtimes for the agents, that coordinate by observing the environment (including the other agents) and deciding for their next move while the other agents continue to execute. **This is what makes a MAS!**

In the PRS model, the deliberation part of the *procedural loop* is given some details: it first transforms the result of the perception into internal variables, called beliefs. It then combines these with a set of goals (remember the BDI architecture by Bratman, Cohen and Levesque) and a set of plans so as to decide for some intention that will be turn into a concrete action in the environment. **Not all MAS adopt such a complex structure**. Actually, BDI agents are a specific case of so-called *cognitive agents* that will be defined later.

**What you must keep in mind** is that an agent:

1. Is **situated** in an environment: it can perceive and act;
2. Continuously performs a **procedural loop**: perception, deliberation, action.

Two or more agents running in the same environment make a **multiagent system**. That's it. The rest depends on the problem you want to solve. Situatedness and procedural loop are what makes an agent.


2. Key Concepts
---------------

There exists a wide range of agent models in the literature. What makes the difference is mostly the level of complexity of the deliberation phase in the procedural loop.

At one extremity of the spectrum are purely **reactive agents**. Such agent do not make use of any internal variable: they directly wire all perception to a specific action (or set of actions), hence their name: they perceive and react.

As you add internal variables and data, you slightly move the cursor toward so-called **cognitive agents**. This name encompasses a very broad set of agent types.

The least cognitive agent will simply use internal variables to store its perception. This means it has a memory of what it perceived, and it can make decisions based on this memory. Its actions are no longer pure reactions: this is the first type of cognitive agents.

The internal variables to store perceptions and, possibly, other values that the agents might compute from the perceptions, are called **beliefs**. This reflects the fact that their value might differ from the value in the environment. Indeed, due to the asynchronous nature of MAS, an agent should never assume that its beliefs corresponds to reality. This has one important consequence on the actions: remember the STRIPS example we saw previously and the plan to catch the bananas:

::

    Move(A,C), MoveBox(C,B), ClimbUp(B), TakeBananas(B)

Nothing prevents, in a MAS, that the box will actually be at position B when the agent tries to climb on it. Indeed, after it moved the box from C to B, another agent might decide to move the box back to C (or to jumb on the box and steal the bananas). For this reason, *cognitive agents must be capable of handling with action failures*. Several options are to be considered:

- The environment returns a success value for the action, which allows the agent to update its beliefs about the action failure for the next procedural loop;
- The environment says nothing but the agent will check the result during the next procedural loop;
- In all cases, the agent must check its next action's precondition to determine if the plan is still valid, and possibly select a different action.

Note that *explicit* planning is not mandatory at this level of cognitive agents. You can imagine that the agent simply checks its current state of beliefs and search for a possible action. The "plan" is then hard-wired in the code. Before we consider explicit planning, there exists other levels of "reasoning" about the beliefs that can be considered. Simple deduction from the beliefs to add some elements in the beliefs base, more complex `belief revision <https://www.cse.huji.ac.il/~lehmann/nonmon/AGM_JSL.ps>`_ when a new perception conflicts with the current belief base, or even `diagnosis <https://www.ijcai.org/Proceedings/81-2/Papers/050.pdf>`_ to identify the source of a failure in the plan, etc. When it comes to explicit planning, *i.e.* agents that have explicit goals and that perform any sort of computation (from simple plan selection in a predefined list to complex planing algorithms such as `SATPLAN <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.9443&rep=rep1&type=pdf>`_), we call these **rational agents**.

There is a spectrum that goes from **reactive** agents to **cognitive** ones and then to **rational** agents.

**Remark:** for now, we do not question the interaction mechanism. This will be done in the third session of the course.

3. To be remembered
-------------------

According to the **PRS model** that is at the core of agent modelling, an agent:

- is **situated** in the environment (it can perceive and act);
- might have some internal data called **beliefs** and these are encapsulated within the agent (they are not accessible to other agents or to the environment);
- runs with a **procedural loop** (perceive, decide for an action, act) in an **asynchronous** w.r.t other agents;
- in the decision phase, it can do any sort of reasoning, from simple reaction (**reactive agents**) to more complex reasoning on the beliefs (**cognitive agents**);
- cognitive agents consider actions with **preconditions and effects** (*note:* this can be way more complex but we shall skip the details for this MAS introductory course);
- agents that have *explicit goals* and *planning procedures* in the deliberation phase are called **rational agents**.

This said, there exists as many different manners of implementing a MAS as there are MAS in the literature. Implementing an agent model generally consists in answering questions for both modelling of the problem and construction of the runtime.  The next subsection guides you through some of these questions.

4. Exercises
------------

Let us begin with two very simple agents in an environment. Please copy-paste the following Python code in your IDE:

.. code:: python
    
    from time import sleep
    
    class Environment:
        def act(self,message):
            print(message)
        def perceive(self):
            pass
    
    class Agent:
        def __init__(self,name,env):
            self.name = name
            self.env = env
        def procedural_loop(self):
            while True:
                self.env.act("Agent "+self.name+" says hello!")
                sleep(0.1)
    
    class Runtime:
        def __init__(self):
            e = Environment()
            (Agent("Alice",e)).procedural_loop()
            (Agent("Bob",e)).procedural_loop()
    
    Runtime()

This code uses Python object-oriented programming: the environment and the agents are defined in two different classes:

- The environment provides perception and action methods that are, in this case, reduced to the display of a value;
- The agents have a simple procedural loop that consists in acting with their own name on the environment;
- The runtime instantiates two agents in the same environment.

.. _question1:

Question
~~~~~~~~

1. Why does this not behave as a multiagent system?
2. What is the problem?

Answer
~~~~~~

Try to answer the question by yourself before you continue. Write down your answers as comments in the code. Discuss with your colleagues and with the teacher.

|
|
|

The answer is available here: :ref:`answer1`.


.. _question2:

Question
~~~~~~~~

To overcome the above limitation, two solutions can be considered. The first one is to write a **scheduler**, *i.e.* a piece of code that calls the procedural loops of all agents, one after the other.

Modify the previous code so that Runtime creates two agents and calls a single-step procedural loop for all agents.


Answer (1)
~~~~~~~~~~

Try to write the code before you go further. Do not simply read the answer.

Here is a first solution: :ref:`answer21`.

In the above solution, you'll notice two things:

1. This MAS verifies a specific property, which is that the procedural loop of all agents is performed at each time step: all agents run at the same "speed".

   This is called a *synchronous* MAS. While the agent has its own runtime, interleaved with the one of the other agents (which corresponds to the specification of a MAS) these runtimes are synchronised.

2. The agents procedural loops are always invoked in the same order, which is not a valid hypothesis in a MAS. Agents should **never** use that property. If you want to avoid this, you can simply modify the ``Runtime`` class as follows:

   .. code:: python

        from random import shuffle
        
        class Runtime:
            def __init__(self):
                e = Environment()
                agents = [Agent("Alice", e), Agent("Bob", e)]
                while True:
                    shuffle(agents)
                    for a in agents:
                        a.procedural_loop()
        
        
    Note that this new version still is a synchronous MAS.

Answer (2)
~~~~~~~~~~

Here is a now a second solution, with an asynchronous MAS that relies on the `Operating System multitasking mechanisms <https://en.wikipedia.org/wiki/Computer_multitasking>`_: :ref:`answer22`.


Note that since both agents have the exact same sleeping time and that the operations performed are quite reduced, they will behave as if in a synchronous MAS. This can be easily changed (although it is of no importance for our situation):

.. code:: python
    
    from random import uniform
    ...
    class Agent(Thread):
        
        def procedural_loop(self):
            ...
            sleep(uniform(0.1,0.5))
    ...

This will make agents have random sleep time. It can simulate a changing time complexity in the procedural loop.


5. Do we have a multiagent system yet?
--------------------------------------

The agents in the preceding example are not really situated since the perception phase does nothing. They use encapsulated data (the agent's name), but we can't really call these a set of beliefs since they are not connected to the perception. Although they have asynchronous runtimes, with a procedural loop, we cannot really call them *agents*, even not *reactive agents*. In order to write reactive agents, we want the deliberation phase, in the procedural loop, to depend on the perceptions.

.. _question3:

Question
~~~~~~~~

Write a new multiagent system, either in the synchronous or in the asynchronous version, in which the environment has some variable that the agents can perceive. Write two reactive agents: the first one increases the variable by a random value when it is even, the other one when it odd.

Test your program.

Answer
~~~~~~

Here is a possible solution: :ref:`answer3`. You might have a different one depending on how you implemented your agents. Just check that all properties in the PRS model are satisfied: situatedness, procedural loop, *etc*.


6. Concurrent modifications
---------------------------

Let us consider the code given in :ref:`answer3`. In this code, agents' runtimes are completely asynchronous. Each agent is a thread. Both agents perceive and act on the value ``v`` in the environment.

Writing asynchronous MAS with threads requires to consider possible concurrent modifications. In our case, you should not see any problem because the agents spend most of their lifetime sleeping. It is very unlikely that two agents run their procedural loops at the exact same time and that the Operating System's scheduler has to interrupt this piece of code.

However, in the general case, you must consider a possible interruption of the following sequence of code:

.. code:: python

    1: self.b = self.env.perceive()    # in Agent.procedural_loop()
    2: if condition_on_b:              # in AgentX.act()
    3:     x = randint(1,4)            # in Environment.increase() -- 4 lines
    4:     print("Agent " + name + " increase the value by "+ str(x))
    5:     self.v = self.v+x
    6:     print("  --> " + str(self.v))


.. _question4:

Questions
~~~~~~~~~

1. What do you expect to be a problem? Explain why.
2. What is a possible solution?

Answers
~~~~~~~

Take the time to think about it. Make propositions to the teacher and to your peers in the (virtual) classroom. Some of the possible interruptions are not a problem in a MAS.

The answer is available here: :ref:`answer4`. It also proposes a solution to handle such concurrent modifications.



1.3. Properties & Definitions
=============================

Before we move to the next important aspects of the course (*i.e.* multiagent interactions), we must consider some important definitions in the domain. All these definitions are related to some crucial questions to be answered before implementing a MAS.

Properties of the Environment
-----------------------------

Fully or partially observable?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Fully observable environments mean that all variables in the environment can be accessed by any agent. This is generally done with some generic mechanism such as:

.. code:: python

    class Environment:
        variables = { 'name1':'value1',
                      'name2':'value2',
                      ... }

        def perceive(self, name):
            return variables[name]
    
        def act(self, name, value):
            variables[name] = value

However, most MAS use *partially observable* environments, in which each agent only accesses a specific set of variables (as was the case in our simple example with Alice and Bob). This is generally done by a set of ad-hoc perception functions that are called by the agents.

Deterministic or stochastic?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

From the agent's point of view, it is always possible that some action has unexpected effects. Indeed, other agents might have changed the outcomes of the action due to their own actions before the first one starts its next perception phase. Let us consider a simple variation on the Alice-Bob example:

.. code:: python

    from threading import Thread
    
    class Environment:
        v = 0
        def act(self):
            self.v = 1 - self.v
            print(self.v)
        def perceive(self):
            return self.v
    
    class Agent(Thread):
        def __init__(self, name, preferred_value, env):
            Thread.__init__(self)
            self.name = name
            self.env = env
            self.pv = preferred_value
        def run(self):
            while True:
                self.procedural_loop()
        def procedural_loop(self):
            if self.env.perceive() != self.pv:
                self.env.act()
    
    class Runtime:
        def __init__(self):
            e = Environment()
            Agent("Alice", 0, e).start()
            Agent("Bob", 1, e).start()
    
    Runtime()
    
In this example, Alice moves ``v`` to 0 every time its value is 1 and Bob does the contrary. From Alice's point of view, and if Bob is quick enough, she perceives that ``v`` is set to 1, changes it to 0 and, during next turn, notices that ``v`` is still at the value 1. She might consider that her action did not have the expected effect.

However, another viewpoint on this implementation is that both Alice and Bob are aware that her actions did work, but that other agents can change the value of ``v``. We can say that their actions are *deterministic* because, from the implementation's point of view, both agents can be assured that their action has the expected effect (and that other agents might counter this effect).

In a *stochastic* environment, some actions have effects that are no guaranteed or not unique. This was partially the case in the initial Alice and Bob example, with an increase in ``v`` that could be any value between 1 and 4. But one can imagine more complex environments in which some action's effects depend on hidden variables so that the result of the action, even when no other agent acts in the environment, is not predictable for the agent. In such MAS, machine learning algorithms can be used to build `Markov Decision Processes <http://web.mit.edu/dimitrib/www/dpchapter.pdf>`_ representations of the MAS behaviour.

Static or dynamic?
~~~~~~~~~~~~~~~~~~

In the Alice and Bob example, the environment does not have any internal process. All changes are performed by the agents. We can say that the environment is *static*. However, in some MAS, it is better to use a *dynamic* environment. One typical example is `ant colony simulation <https://www.academia.edu/download/56730281/DrogoulMaamaw92.pdf>`_ in which pheromons dropped by the agents in the environment need to spread and evaporate with time. The `Netlogo platform <https://ccl.northwestern.edu/netlogo/>`_ supports this mechanism natively.

Discrete or continuous?
~~~~~~~~~~~~~~~~~~~~~~~

As in most modelling problem, computer science systems deal with the discrete *vs* continuous question. However, in multiagent systems, this question comes to a particular level, as far as actions in the environment are considered. In the Alice and Bob example, the number of possible actions and perceptions is fixed and finite. This is the case in most MAS and we can say that we have a *discrete* environments. However, some problems require the environment to support an infinite set of actions, possibly with continuous values as parameters.


Properties of the Agents in the MAS
-----------------------------------

Autonomous agents
~~~~~~~~~~~~~~~~~

*Autonomy* in a Multi-Agent Systems does not mean that the agents can do whatever they want to. To begin with, all agents behave according to a well-defined program. Autonomy must be understood as the independence of one agent's behaviour (*i.e.* action selection) with respect to some part of the system. Understanding this concept requires to consider different levels.

- At the agent level, pro-action is the first degree of autonomy. Cognitive agents can decide to perform an action due to some internal process changing their belief base. In that case, the agent can trigger some action in the environment in a pro-active manner, *i.e.* independently from any specific signal from the environment. Imagine an agent that plays hide and seek and that begins seeking after ending a countdown. This is a (very simple) example of pro-action.
- At the interaction level, although we have not discussed interaction mechanisms yet, autonomy consists in having agents that do not necessarily accept other agent's requests. Like in human communication, several situations can occur: the agent deliberately ignores the message because it is considered irrelevant; the agent does not answer immediately while it could have; the agent answers but refuses the request; *etc*.
- At the MAS level, there is no autonomy: agents are not autonomous *w.r.t.* the system. On the contrary, they perform what they are designed for. They follow well-defined protocols so that the global task is achieved. Otherwise, there is some misconception in the system.


Loosely vs tightly coupled?
~~~~~~~~~~~~~~~~~~~~~~~~~~~

From the software engineering point of view, several approaches can be considered when designing the agents behaviour. In tightly coupled MAS, the developer has a complete view of the MAS, of possible actions performed by other agents. In other words, it can use some of this information to design action mechanism in a more efficient manner. On the contrary, in a loosely coupled MAS, you must make no assumption on the design of other agents in the MAS. This means that you must define very robust behaviours to avoid deadlocks, infinite loops or unnecessary waiting times in communication. We will see several examples in the third session of this course.

Open MAS?
~~~~~~~~~

Open multi-agent systems are a specific kind of system in which you assume that agents can enter and leave the system at any time during the execution. This hypothesis requires programmers to design specific mechanism to ensure that messages are not left unanswered, that some feature in the system will not disappear when not expected, *etc*. While many MAS are closed, the most platforms support the addition and deletion of agents at runtime. The difficulty lies in the programming of the agents themselves to avoid inconsistent behaviours in the system.

Concrete examples of *open* MAS are ant colonies or prey-predator simulations, such as what we will do in the next session of this course.

Distributed systems?
~~~~~~~~~~~~~~~~~~~~

Distribution in a MAS is a very difficult question, because it can be addressed at different levels. The first, and most important level, is the *conceptual* one. One can perfectly design a MAS that runs in a single thread. Here is the Alice-Bob example from above in its mono-thread version:

.. code:: python

    from random import shuffle
    
    class Environment:
        v = 0
        def act(self):
            self.v = 1 - self.v
            print(self.v)
        def perceive(self):
            return self.v
    
    class Agent:
        def __init__(self, name, preferred_value, env):
            self.name = name
            self.env = env
            self.pv = preferred_value
        def procedural_loop(self):
            if self.env.perceive() != self.pv:
                self.env.act()
    
    class Runtime:
        agents_list = []
        def __init__(self):
            e = Environment()
            self.agents_list.append(Agent("Alice", 0, e))
            self.agents_list.append(Agent("Bob", 1, e))
        def run(self):
            while(True):
                shuffle(self.agents_list)
                for a in self.agents_list:
                    a.procedural_loop()
    
    r = Runtime()
    r.run()
    

Not all MAS are multi-threaded. What matters is that it implements distribution principles that were presented in the first section of this course: encapsulated data, accessed via perception and action methods only, using a *procedural loop* that interleaves the perceptions and actions of agents. This is distribution at a conceptual level. Most MAS implemented in `Netlogo <https://ccl.northwestern.edu/netlogo/>`_ or `Gamma <https://gama-platform.github.io/>`_ stay at this level and it is perfectly right!

This said, distribution can also be considered at the *software level*. This is what we achieve with threads: agents get separated in different threads or processes (depending on the language and implementation). These threads generally run on a single computer. They share its computation time, thanks to the OS scheduler, so as to perform their operations. Most MAS implemented in `Repast Symphony <https://repast.github.io/>`_ are distributed at the software level (and, of course, at the conceptual level).

A third level of distribution can also be considered. It is more difficult to achieve and not all platforms support it. It is the *physical distribution*. Imagine a group of robots that participate in a collective task, a network of smart sensors that exchange information with each other or even living creatures such as social insects (bees, ants...) or human beings. They all share a common physical environment and interact with each other. Such systems are distributed at the physical level.

Implementing such systems (robots, sensors, distributed services or simulation that requires physical distribution) is often difficult because you will need specific code to connect the abstract actions and perceptions to physical operations, message passing, *etc*. The most famous platforms you can use to make this task easier are:

- The Java Agent Development Environment (`Jade <https://jade.tilab.com/>`_) which is a Java API to run multi-threaded, multi-systems applications with brokers for message passing. It is widely used for implementing networked applications (sensor networks, distributed simulation or services).
- The Robot OS (`ROS <https://www.ros.org/>`_) which provides a set of tools to ease the implementation and simulation of robotic systems and robots in a physical environment. The resulting code can be easily transferred to physical robots.


Concluding remarks
------------------

At this point in the course, you figured out that MAS programming is largely a question of design patterns to implement a distributed system with some interesting properties. You can implement a MAS in plain C if you want. Thread, classes, or even more complex features are all compiled to assembler language in the end. However, computer scientists generally rely on high-level models and multi-agent platforms to make agent based programming easier. A multi-agent platform implements the scheduler, the procedural loop and the interaction mechanisms that we will see in the third session of this course. Some of them rely on existing languages (*e.g.* `Repast Symphony <https://repast.github.io/>`_ or `Jade <https://jade.tilab.com/>`_ for Java, `Mesa <https://mesa.readthedocs.io/en/master/>`_ or `Spade <https://spade-mas.readthedocs.io/>`_ for Python). Some other define dedicated languages to get rid of the initial language's hassle: this is the case for `Netlogo <https://ccl.northwestern.edu/netlogo/>`_ or `Gamma <https://gama-platform.github.io/>`_ (both are initially programmed in Java).

The idea with platforms is to avoid programmers to rewrite the basic mechanisms in MAS. This principle is at the basis of C/C++/C# libraries, or Java APIs, or Python modules. When such libraries get complex enough and take control over the runtime, we call them platforms. In the next section, we will introduce the Mesa platform for Python.


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Wassila Ouerdane | Research</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/cufon-yui.js"></script>
<script type="text/javascript" src="js/georgia.js"></script>
<script type="text/javascript" src="js/cuf_run.js"></script>
</head>
<body>
<div class="main">
  <div class="header">
    <div class="header_resize">
      <div class="logo">
        <h1><a href="index.html"><span>W</span>assila Ouerdane<br />
          <small>Maitre de conferences</small></a></h1>
      </div>
      <div class="menu">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="research.html" class="active">Research</a></li>
          <li><a href="publication2.html">Publication</a></li>
<li><a href="teaching2.html">Teaching</a></li>
          </ul>
      </div>
      <div class="clr"></div>
    </div>

    <div class="headert_text_resize_bg">
      <div class="headert_text_resize"> <img src="images/img_simple.jpg" alt="" width="380" height="231" />
        
      </div>
    </div>
    <div class="clr"></div>
  </div>
  <div class="body">
    <div class="body_resize">
     <div class="left">

        <h2>Topics of interest</h2>
       
        <p align="justify">


My main research interests include multiple criteria decision analysis, argumentation theory, Artificial Intelligence and decision aiding process. More precisely, it concerns: 



<ul> 

<li>  <p align="justify"> <strong>Adaptive Explanation of Algorithmic Decisions</strong>. The ability to provide explanations along with recommended decisions to the user is a key feature of decision-aiding tools. Roughly, speaking, the aim is to increase the user's acceptance of the recommended choice, by providing supporting evidence that this choice is justified. One of the difficulty of this question lies on the fact that the relevant concept 
of an explanation may be different, depending on the problem at hand and on the targeted audience. The main challenges are: 

<ul>
<li> <p align="justify"> <strong>Dealing with the variety of decision models</strong>. Often a system designs a single explanation strategy, dedicated to the decision model implemented by the system. Our ambition is to provide a catalogue of explanation options that can be used in different contexts (supported by the existence of a large panel of multiple criteria decision models)</li> </p>

<li> <p align="justify"><strong> Dealing with the variety of users' profiles</strong>. Each of the explanation option mentioned in the previous point can be filtered so as to match a specific user profile. The idea of tailoring explanations (e.g. finding the good level of abstraction) for a given user is not new in itself, but the idea is to provide a unique catalogue, depending on the decision model. 
 </li> </p>
</ul>

</li> </p>


	
<li>  <p align="justify"> <strong> Models for adaptive interaction</strong>.  In the classical flow envisioned in decision-support systems, three phases are sequentially identified: elicitation, recommendation, and finally explanation. The aim is to provide an integrated model where explanations can be provided during the elicitation process. Such explanations may be partial, and may be used to guide the elicitation, provided the user is convinced by the justification of the system.  The main issues are: i) how to design the interaction between a system and a human decision maker (dialogue game protocol), and ii) How to adapt classical elicitation algorithms that can cope with inconsistent user feedback, by automatically adjusting the model to the preference information provided by the user? 
</li></p>

<li>  <p align="justify"> <strong>Designing and applying decision aiding methodology</strong>. Through the previous points our ambition is to get solid theoretical frameworks.  Beyond this, we wish to prove the usefulness and the applicability of our proposals through real situations. Actually, we investigate the fields of: Risk Analysis and Project Management, and Rules-based systems, where we try to use some methodologies and tools based on MCDA (Multiple criteria Decision Aiding) and AI to model and solve some real decision problems.
</li> </p>

</p>
      </div>
     







<div class="left">

       
       
  <h2>Current PhD students</h2>
       
       
<p align="justify">

<ul>
	


	<li> <p align="justify"> Ali Tlili. Multicriteria Portfolio Management Optimization.  Thèse CIFRE (Dassault Systèmes). 
		Co-encadrement avec Vincent Mousseau (CentraleSupélec), Khaled Oumeima (Dassault Systèmes) (Start November 2018). 
		</p> </li>

	<li> <p align="justify"> Pegdwendé Stéphane MINOUNGOU. Integrating Explanation and Elicitation of recommendations for
decisions support. (Thèse CIFRE IBM). Co-encadrement avec Vincent Mousseau (CentraleSupélec), Paolo Scoton (IBM Zurich) (Start January 2019). 

	</p> </li>
	</ul>

</p>

  <h2>Past PhD students</h2>
       
       
<p align="justify">

<ul>


	
<li> <p align="justify"> 	Manel Maamar. (7/12/2015). Modélisation et optimisation multicritère avec anticipation
d’une place de marché de Leads. Thèse CIFRE (Place des Leads). Co-encadrement avec
Vincent Mousseau (50%).</p> </li>

	<li> <p align="justify"> Jinyan Liu (9/03/2016). Elicitation de préférences pour un modèle à base de points de
références. Bourse CSC. CentraleSupéléec. Co-encadrement avec Vincent Mousseau
(60%).</p> </li>

		<li> <p align="justify"> Karim El Mernissi (13/12/2017). Génération d’explications dans les systèmes à base de
règles. Thèse CIFRE (IBM). Université Pierre et Marie Curie. Co-encadrement Nicolas
Maudet (50%).</p> </li>

			<li> <p align="justify"> Massinissa Mammeri (28/11/2017). Decision aiding methodology for developing the contractual
strategy of complex oil and gas projects. Thèse CIFRE (TOTAL). CentraleSupélec.
Co-encadrement avec Franck Marle (50%).</p> </li>


	<li> <p align="justify">	Khaled Belahcene (05/12/2018). A contribution to accountable decision aiding : explanations
for the aggregation of preferences. CentraleSupélec. Co-encadrement (25%) avec
Vincent Mousseau (CentraleSupélec), Nicolas Maudet (Sorbonne Université), Christophe
Labreuche (Thales Research and Technology).</p> </li>
	
	
</ul>

</p>


     
</div>
     
<div>  

</div>


</body>



   

</html>



